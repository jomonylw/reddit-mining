#!/usr/bin/env python3
"""
LLM Pipeline éªŒè¯æµ‹è¯•è„šæœ¬
æµ‹è¯•ç—›ç‚¹åˆ†æå¤„ç†æµç¨‹çš„å®Œæ•´æ€§
"""

import os
import sys
import json
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.llm.prompts import SYSTEM_PROMPT, build_user_prompt, format_comments
from src.llm.client import LLMClient
from src.models.schemas import AnalysisResult, PainPointExtraction, Score, ScoresDict


def test_prompt_generation():
    """æµ‹è¯• Prompt ç”Ÿæˆ"""
    print("=" * 60)
    print("æµ‹è¯• 1: Prompt æ¨¡æ¿ç”Ÿæˆ")
    print("=" * 60)
    
    sample_post = {
        "title": "I'm so frustrated with my project management tool - it keeps losing my data!",
        "selftext": "Every time I try to save my project timeline, the software crashes and I lose all my work. I've tried reinstalling but nothing helps. Is there any reliable alternative?",
        "subreddit": "projectmanagement",
        "score": 150,
        "num_comments": 45
    }
    
    top_comments = format_comments([
        "Same here, I switched to Notion last month and never looked back.",
        "This is a known bug, they've been promising a fix for months."
    ])
    
    user_prompt = build_user_prompt(
        subreddit=sample_post["subreddit"],
        title=sample_post["title"],
        content=sample_post["selftext"],
        score=sample_post["score"],
        num_comments=sample_post["num_comments"],
        top_comments=top_comments
    )
    
    print("\n[ç³»ç»Ÿæç¤ºè¯é¢„è§ˆ (å‰500å­—ç¬¦)]:")
    print(SYSTEM_PROMPT[:500] + "...")
    
    print("\n[ç”¨æˆ·æç¤ºè¯]:")
    print(user_prompt)
    
    print("\nâœ… Prompt ç”Ÿæˆæµ‹è¯•é€šè¿‡")
    return True


def test_schema_validation():
    """æµ‹è¯• Schema éªŒè¯"""
    print("\n" + "=" * 60)
    print("æµ‹è¯• 2: Pydantic Schema éªŒè¯")
    print("=" * 60)
    
    # æ„å»ºæœ‰æ•ˆçš„ ScoresDict
    valid_scores = ScoresDict(
        urgency=Score(score=8, reason="ç”¨æˆ·è¡¨è¾¾äº†å¼ºçƒˆçš„æŒ«è´¥æ„Ÿ"),
        frequency=Score(score=7, reason="æ¯æ¬¡ä¿å­˜éƒ½ä¼šå‡ºç°é—®é¢˜"),
        market_size=Score(score=6, reason="é¡¹ç›®ç®¡ç†æ˜¯å¸¸è§éœ€æ±‚"),
        monetization=Score(score=5, reason="ç”¨æˆ·æ„¿æ„å°è¯•æ›¿ä»£å“"),
        barrier_to_entry=Score(score=5, reason="éœ€è¦ä¸€å®šçš„æŠ€æœ¯ç§¯ç´¯")
    )
    
    # æµ‹è¯•æœ‰æ•ˆçš„ç—›ç‚¹æå–ç»“æœ
    valid_pain_point = PainPointExtraction(
        title="é¡¹ç›®ç®¡ç†è½¯ä»¶æ•°æ®ä¸¢å¤±é—®é¢˜",
        description="ç”¨æˆ·åœ¨ä½¿ç”¨é¡¹ç›®ç®¡ç†å·¥å…·æ—¶é‡åˆ°é¢‘ç¹çš„æ•°æ®ä¿å­˜å¤±è´¥å’Œè½¯ä»¶å´©æºƒé—®é¢˜ï¼Œå¯¼è‡´å·¥ä½œè¿›åº¦ä¸¢å¤±ã€‚",
        user_need="éœ€è¦ä¸€ä¸ªç¨³å®šå¯é çš„é¡¹ç›®ç®¡ç†å·¥å…·",
        current_solution="å°è¯•é‡æ–°å®‰è£…è½¯ä»¶",
        ideal_solution="è‡ªåŠ¨ä¿å­˜å’Œäº‘ç«¯åŒæ­¥",
        industry_code="PRODUCTIVITY",
        type_code="RELIABILITY",
        tags=["æ•°æ®ä¸¢å¤±", "è½¯ä»¶å´©æºƒ", "é¡¹ç›®ç®¡ç†", "ç”¨æˆ·ä½“éªŒ"],
        mentioned_competitors=["Notion"],
        quotes=["it keeps losing my data", "the software crashes"],
        target_personas=["é¡¹ç›®ç»ç†", "å›¢é˜Ÿè´Ÿè´£äºº"],
        actionable_insights=["å¼€å‘è‡ªåŠ¨ä¿å­˜åŠŸèƒ½", "å¢åŠ æœ¬åœ°ç¼“å­˜"],
        scores=valid_scores
    )
    
    try:
        print("\n[PainPointExtraction éªŒè¯]:")
        print(f"  - title: {valid_pain_point.title}")
        print(f"  - industry_code: {valid_pain_point.industry_code}")
        print(f"  - type_code: {valid_pain_point.type_code}")
        print(f"  - tags: {valid_pain_point.tags}")
        print("\nâœ… PainPointExtraction éªŒè¯é€šè¿‡")
    except Exception as e:
        print(f"\nâŒ PainPointExtraction éªŒè¯å¤±è´¥: {e}")
        return False
    
    # æµ‹è¯•æœ‰æ•ˆçš„åˆ†æç»“æœï¼ˆåŒ…å«ç—›ç‚¹ï¼‰
    valid_result = AnalysisResult(
        is_pain_point=True,
        confidence=0.85,
        reason="ç”¨æˆ·æ˜ç¡®è¡¨è¾¾äº†å¯¹é¡¹ç›®ç®¡ç†å·¥å…·çš„ä¸æ»¡ï¼Œæè¿°äº†å…·ä½“çš„æ•°æ®ä¸¢å¤±é—®é¢˜",
        pain_point=valid_pain_point
    )
    
    try:
        print("\n[æœ‰æ•ˆ AnalysisResult éªŒè¯]:")
        print(f"  - is_pain_point: {valid_result.is_pain_point}")
        print(f"  - confidence: {valid_result.confidence}")
        print(f"  - reason: {valid_result.reason[:50]}...")
        print(f"  - pain_point.title: {valid_result.pain_point.title}")
        print("\nâœ… æœ‰æ•ˆ AnalysisResult éªŒè¯é€šè¿‡")
    except Exception as e:
        print(f"\nâŒ æœ‰æ•ˆ AnalysisResult éªŒè¯å¤±è´¥: {e}")
        return False
    
    # æµ‹è¯•éç—›ç‚¹ç»“æœ
    non_pain_point = AnalysisResult(
        is_pain_point=False,
        confidence=0.9,
        reason="å¸–å­æ˜¯ä¸€ä¸ªç®€å•çš„æŠ€æœ¯å’¨è¯¢é—®é¢˜",
        pain_point=None
    )
    
    try:
        print("\n[éç—›ç‚¹ç»“æœéªŒè¯]:")
        print(f"  - is_pain_point: {non_pain_point.is_pain_point}")
        print(f"  - confidence: {non_pain_point.confidence}")
        print(f"  - pain_point: {non_pain_point.pain_point}")
        print("\nâœ… éç—›ç‚¹ç»“æœéªŒè¯é€šè¿‡")
    except Exception as e:
        print(f"\nâŒ éç—›ç‚¹ç»“æœéªŒè¯å¤±è´¥: {e}")
        return False
    
    # æµ‹è¯•ç½®ä¿¡åº¦èŒƒå›´éªŒè¯
    print("\n[ç½®ä¿¡åº¦èŒƒå›´éªŒè¯]:")
    try:
        AnalysisResult(
            is_pain_point=True,
            confidence=1.5,  # è¶…å‡ºèŒƒå›´
            reason="æµ‹è¯•",
            pain_point=None
        )
        print("  âŒ åº”è¯¥æ‹’ç» confidence > 1.0")
        return False
    except ValueError as e:
        print(f"  âœ… æ­£ç¡®æ‹’ç»æ— æ•ˆç½®ä¿¡åº¦: {e}")
    
    return True


def test_llm_client_initialization():
    """æµ‹è¯• LLM å®¢æˆ·ç«¯åˆå§‹åŒ–"""
    print("\n" + "=" * 60)
    print("æµ‹è¯• 3: LLM å®¢æˆ·ç«¯åˆå§‹åŒ–")
    print("=" * 60)
    
    api_key = os.getenv("LLM_API_KEY") or os.getenv("OPENAI_API_KEY")
    
    if not api_key:
        print("\nâš ï¸  æœªé…ç½® LLM_API_KEYï¼Œè·³è¿‡å®¢æˆ·ç«¯åˆå§‹åŒ–æµ‹è¯•")
        print("   è®¾ç½®ç¯å¢ƒå˜é‡åå¯è¿›è¡Œå®Œæ•´æµ‹è¯•:")
        print("   export LLM_API_KEY=your_api_key")
        return True
    
    try:
        client = LLMClient(api_key=api_key)
        print(f"\n[å®¢æˆ·ç«¯é…ç½®]:")
        print(f"  - Base URL: {client.base_url}")
        print(f"  - Model: {client.model}")
        print(f"  - Temperature: {client.temperature}")
        print(f"  - Max Tokens: {client.max_tokens}")
        print("\nâœ… LLM å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
        return True
    except Exception as e:
        print(f"\nâŒ LLM å®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
        return False


def test_llm_analysis(run_actual=False):
    """æµ‹è¯• LLM åˆ†æåŠŸèƒ½ï¼ˆå¯é€‰å®é™…è°ƒç”¨ï¼‰"""
    print("\n" + "=" * 60)
    print("æµ‹è¯• 4: LLM åˆ†æåŠŸèƒ½")
    print("=" * 60)
    
    api_key = os.getenv("LLM_API_KEY") or os.getenv("OPENAI_API_KEY")
    
    if not api_key or not run_actual:
        print("\nâš ï¸  è·³è¿‡å®é™… LLM è°ƒç”¨æµ‹è¯•")
        if not api_key:
            print("   åŸå› : æœªé…ç½® LLM_API_KEY")
        if not run_actual:
            print("   åŸå› : run_actual=False (é¿å…æ¶ˆè€— API é…é¢)")
        print("   è¿è¡Œå®Œæ•´æµ‹è¯•: python test_llm_pipeline.py --run-llm")
        return True
    
    sample_post = {
        "title": "Why is every SaaS tool subscription-based now? I just want to buy software once!",
        "selftext": "I'm tired of paying monthly fees for everything. My design software, my email client, my note-taking app - everything wants a subscription. Whatever happened to buying software once and owning it forever?",
        "subreddit": "software",
        "score": 523,
        "num_comments": 189
    }
    
    try:
        client = LLMClient(api_key=api_key)
        
        print("\n[å‘é€åˆ†æè¯·æ±‚...]")
        result = client.analyze_post(sample_post)
        
        print("\n[åˆ†æç»“æœ]:")
        print(json.dumps(result.model_dump(), ensure_ascii=False, indent=2))
        
        # éªŒè¯ç»“æœ
        assert isinstance(result.is_pain_point, bool), "is_pain_point åº”ä¸ºå¸ƒå°”å€¼"
        assert 0 <= result.confidence <= 1, "confidence åº”åœ¨ 0-1 ä¹‹é—´"
        
        if result.is_pain_point:
            assert result.title, "ç—›ç‚¹åº”æœ‰æ ‡é¢˜"
            assert result.description, "ç—›ç‚¹åº”æœ‰æè¿°"
            assert result.pain_point_type, "ç—›ç‚¹åº”æœ‰ç±»å‹"
            print("\nâœ… LLM åˆ†æç»“æœéªŒè¯é€šè¿‡")
        else:
            print("\nâœ… å¸–å­è¢«åˆ¤å®šä¸ºéç—›ç‚¹ï¼Œç»“æœæœ‰æ•ˆ")
        
        return True
    except Exception as e:
        print(f"\nâŒ LLM åˆ†æå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_chinese_output():
    """éªŒè¯ä¸­æ–‡è¾“å‡º"""
    print("\n" + "=" * 60)
    print("æµ‹è¯• 5: ä¸­æ–‡è¾“å‡ºéªŒè¯")
    print("=" * 60)
    
    # æ£€æŸ¥ç³»ç»Ÿæç¤ºè¯åŒ…å«ä¸­æ–‡æŒ‡ä»¤
    chinese_keywords = ["ä¸­æ–‡", "ç®€ä½“ä¸­æ–‡", "Chinese"]
    found = any(kw in SYSTEM_PROMPT for kw in chinese_keywords)
    
    print(f"\n[ç³»ç»Ÿæç¤ºè¯ä¸­æ–‡æŒ‡ä»¤æ£€æŸ¥]: {'âœ… åŒ…å«ä¸­æ–‡è¾“å‡ºæŒ‡ä»¤' if found else 'âŒ æœªæ‰¾åˆ°ä¸­æ–‡è¾“å‡ºæŒ‡ä»¤'}")
    
    # æ„å»ºä¸­æ–‡å†…å®¹çš„ç—›ç‚¹
    sample_scores = ScoresDict(
        urgency=Score(score=7, reason="ç”¨æˆ·è¡¨è¾¾äº†æ˜ç¡®ä¸æ»¡"),
        frequency=Score(score=6, reason="æŒç»­æ€§é—®é¢˜"),
        market_size=Score(score=8, reason="å½±å“å¤§å¤šæ•°è½¯ä»¶ç”¨æˆ·"),
        monetization=Score(score=5, reason="æœ‰ä¸€å®šä»˜è´¹æ„æ„¿"),
        barrier_to_entry=Score(score=4, reason="é—¨æ§›é€‚ä¸­")
    )
    
    sample_pain_point = PainPointExtraction(
        title="SaaSè½¯ä»¶è®¢é˜…åˆ¶æ”¶è´¹æ¨¡å¼å¼•å‘ç”¨æˆ·ä¸æ»¡",
        description="ç”¨æˆ·å¯¹è½¯ä»¶è¡Œä¸šæ™®éé‡‡ç”¨çš„è®¢é˜…åˆ¶æ”¶è´¹æ¨¡å¼è¡¨ç¤ºä¸æ»¡ï¼Œå¸Œæœ›èƒ½ä¸€æ¬¡æ€§è´­ä¹°æ°¸ä¹…ä½¿ç”¨æƒã€‚",
        user_need="ä¸€æ¬¡æ€§è´­ä¹°è½¯ä»¶",
        industry_code="SAAS",
        type_code="HIGH_COST",
        tags=["è®¢é˜…åˆ¶", "è½¯ä»¶å®šä»·", "ç”¨æˆ·ä¸æ»¡", "SaaS"],
        scores=sample_scores
    )
    
    sample_result = AnalysisResult(
        is_pain_point=True,
        confidence=0.9,
        reason="ç”¨æˆ·å¯¹è®¢é˜…åˆ¶æ”¶è´¹æ¨¡å¼è¡¨è¾¾äº†æ˜ç¡®ä¸æ»¡",
        pain_point=sample_pain_point
    )
    
    # éªŒè¯ä¸­æ–‡å†…å®¹
    assert any('\u4e00' <= char <= '\u9fff' for char in sample_result.pain_point.title), "æ ‡é¢˜åº”åŒ…å«ä¸­æ–‡"
    assert any('\u4e00' <= char <= '\u9fff' for char in sample_result.pain_point.description), "æè¿°åº”åŒ…å«ä¸­æ–‡"
    
    print("\n[ä¸­æ–‡å†…å®¹ç¤ºä¾‹]:")
    print(f"  - æ ‡é¢˜: {sample_result.pain_point.title}")
    print(f"  - ç±»å‹: {sample_result.pain_point.type_code}")
    print(f"  - è¡Œä¸š: {sample_result.pain_point.industry_code}")
    print(f"  - æ ‡ç­¾: {sample_result.pain_point.tags}")
    
    print("\nâœ… ä¸­æ–‡è¾“å‡ºéªŒè¯é€šè¿‡")
    return True


def run_all_tests():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("\n" + "=" * 60)
    print("ğŸš€ LLM Pipeline éªŒè¯æµ‹è¯•")
    print(f"   æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 60)
    
    run_llm = "--run-llm" in sys.argv
    
    results = []
    results.append(("Prompt æ¨¡æ¿ç”Ÿæˆ", test_prompt_generation()))
    results.append(("Schema éªŒè¯", test_schema_validation()))
    results.append(("LLM å®¢æˆ·ç«¯åˆå§‹åŒ–", test_llm_client_initialization()))
    results.append(("LLM åˆ†æåŠŸèƒ½", test_llm_analysis(run_actual=run_llm)))
    results.append(("ä¸­æ–‡è¾“å‡ºéªŒè¯", test_chinese_output()))
    
    # æ±‡æ€»ç»“æœ
    print("\n" + "=" * 60)
    print("ğŸ“Š æµ‹è¯•ç»“æœæ±‡æ€»")
    print("=" * 60)
    
    passed = sum(1 for _, r in results if r)
    total = len(results)
    
    for name, result in results:
        status = "âœ… PASS" if result else "âŒ FAIL"
        print(f"  {status} - {name}")
    
    print(f"\næ€»è®¡: {passed}/{total} æµ‹è¯•é€šè¿‡")
    
    if passed == total:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼LLM Pipeline å°±ç»ªã€‚")
        return 0
    else:
        print("\nâš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®ã€‚")
        return 1


if __name__ == "__main__":
    sys.exit(run_all_tests())